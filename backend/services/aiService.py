import base64
import asyncio
import os
from dotenv import load_dotenv
from emergentintegrations.llm.openai.image_generation import OpenAIImageGeneration

# Load environment variables
load_dotenv()

class AIService:
    def __init__(self):
        # Get the Emergent LLM key
        self.api_key = os.getenv('EMERGENT_LLM_KEY')
        if not self.api_key:
            raise ValueError("EMERGENT_LLM_KEY not found in environment variables")
        
        # Initialize OpenAI image generation
        self.image_generator = OpenAIImageGeneration(api_key=self.api_key)

    async def generateImage(self, prompt: str, mode: str = "text-to-image", input_image: str = None):
        """
        Generate image using OpenAI DALL-E through Emergent LLM Key
        
        Args:
            prompt (str): Text prompt for image generation
            mode (str): Generation mode ('text-to-image' or 'image-to-image')
            input_image (str): Base64 or URL of input image (currently not used for DALL-E)
            
        Returns:
            dict: Generation result with success status and image data
        """
        start_time = asyncio.get_event_loop().time()
        
        try:
            print(f"🎨 Generating image with DALL-E: '{prompt[:50]}...'")
            
            # Enhance prompt for better results
            enhanced_prompt = self._enhance_prompt(prompt)
            
            # Generate image using DALL-E
            images = await self.image_generator.generate_images(
                prompt=enhanced_prompt,
                model="gpt-image-1",  # Latest DALL-E model
                number_of_images=1
            )
            
            if not images or len(images) == 0:
                raise Exception("No image was generated by DALL-E")
            
            # Convert to base64 for easy handling
            image_base64 = base64.b64encode(images[0]).decode('utf-8')
            image_data_url = f"data:image/png;base64,{image_base64}"
            
            end_time = asyncio.get_event_loop().time()
            processing_time = (end_time - start_time) * 1000  # Convert to milliseconds
            
            print(f"✅ Image generated successfully in {processing_time:.1f}ms")
            
            return {
                'success': True,
                'images': [image_data_url],
                'processingTime': processing_time,
                'metadata': {
                    'model': 'dall-e-3-via-emergent',
                    'enhanced_prompt': enhanced_prompt,
                    'original_prompt': prompt,
                    'mode': mode,
                    'image_format': 'base64_data_url'
                }
            }
            
        except Exception as error:
            end_time = asyncio.get_event_loop().time()
            processing_time = (end_time - start_time) * 1000
            
            print(f"❌ Image generation failed: {str(error)}")
            
            return {
                'success': False,
                'error': f'AI image generation failed: {str(error)}',
                'processingTime': processing_time,
                'metadata': {
                    'model': 'dall-e-3-via-emergent',
                    'prompt': prompt,
                    'mode': mode
                }
            }

    def _enhance_prompt(self, prompt: str) -> str:
        """
        Enhance the user prompt for better DALL-E results
        
        Args:
            prompt (str): Original user prompt
            
        Returns:
            str: Enhanced prompt with quality modifiers
        """
        # Don't enhance if prompt is already detailed
        if len(prompt.split()) > 15:
            return prompt
            
        # Add quality enhancers for better results
        quality_enhancers = [
            "highly detailed",
            "professional quality", 
            "8k resolution",
            "stunning composition"
        ]
        
        # Add style context based on content
        if any(word in prompt.lower() for word in ['landscape', 'mountain', 'nature', 'forest', 'ocean']):
            enhanced = f"{prompt}, {', '.join(quality_enhancers[:2])}, natural lighting, photorealistic"
        elif any(word in prompt.lower() for word in ['portrait', 'person', 'character', 'face']):
            enhanced = f"{prompt}, {', '.join(quality_enhancers)}, professional portrait lighting"
        elif any(word in prompt.lower() for word in ['art', 'painting', 'drawing', 'artistic']):
            enhanced = f"{prompt}, {', '.join(quality_enhancers)}, masterpiece, fine art"
        else:
            enhanced = f"{prompt}, {', '.join(quality_enhancers[:3])}"
            
        return enhanced

    async def processImageToImage(self, image_path: str, prompt: str):
        """
        Process image-to-image generation
        Note: DALL-E doesn't directly support image-to-image, so we'll use text-to-image with descriptive prompt
        
        Args:
            image_path (str): Path to input image (for future reference)
            prompt (str): Text prompt for modifications
            
        Returns:
            dict: Processing result
        """
        try:
            # For now, treat as text-to-image since DALL-E 3 doesn't support image editing in the same way
            # In the future, this could be enhanced with image analysis + prompt combination
            enhanced_prompt = f"Create an image based on this description: {prompt}"
            return await self.generateImage(enhanced_prompt, 'image-to-image', image_path)
            
        except Exception as error:
            print(f"❌ Image-to-Image processing error: {str(error)}")
            return {
                'success': False,
                'error': f'Image processing failed: {str(error)}'
            }

    async def getGenerationStatus(self, generation_id: str):
        """
        Get generation status (for real-time updates)
        Since DALL-E generation is synchronous, this returns completed status
        
        Args:
            generation_id (str): Generation identifier
            
        Returns:
            dict: Status information
        """
        return {
            'id': generation_id,
            'status': 'completed',
            'progress': 100,
            'estimatedTime': 0,
            'provider': 'dall-e-3-via-emergent'
        }

    def validateGenerationParams(self, prompt: str, mode: str) -> list:
        """
        Validate image generation parameters
        
        Args:
            prompt (str): Text prompt
            mode (str): Generation mode
            
        Returns:
            list: Array of validation errors
        """
        errors = []
        
        if not prompt or prompt.strip() == '':
            errors.append('Prompt cannot be empty')
        
        if prompt and len(prompt.strip()) < 3:
            errors.append('Prompt must be at least 3 characters long')
        
        if prompt and len(prompt) > 1000:
            errors.append('Prompt must be less than 1000 characters')
        
        if mode and mode not in ['text-to-image', 'image-to-image']:
            errors.append('Invalid generation mode')
            
        return errors

# Create a singleton instance
aiService = AIService()